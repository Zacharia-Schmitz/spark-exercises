{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydataset import data as pyd\n",
    "from vega_datasets import data as vega\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[language: string]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create spark dataframe \n",
    "df = spark.createDataFrame(\n",
    "    pd.DataFrame(\n",
    "        dict(language=[\n",
    "            'python',\n",
    "            'sql',\n",
    "            'html',\n",
    "            'css',\n",
    "            'javascript',\n",
    "            'ruby',\n",
    "            'c++'])\n",
    "    )\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Language: string (nullable = true)\n",
      " |-- Popularity: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  10\n",
      "Number of columns:  2\n",
      "+----------+----------+\n",
      "|  Language|Popularity|\n",
      "+----------+----------+\n",
      "|      Java|         1|\n",
      "|    Python|         2|\n",
      "|JavaScript|         3|\n",
      "|        C#|         4|\n",
      "|       PHP|         5|\n",
      "+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View the schema of the dataframe\n",
    "# Output the shape of the dataframe\n",
    "# Show the first 5 records in the dataframe\n",
    "\n",
    "# view the schema of the dataframe\n",
    "df.printSchema()\n",
    "\n",
    "# output the shape of the dataframe\n",
    "print(\"Number of rows: \", df.count())\n",
    "print(\"Number of columns: \", len(df.columns))\n",
    "\n",
    "# show the first 5 records in the dataframe\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2. \n",
    "\n",
    "Load the mpg dataset as a spark dataframe.\n",
    "\n",
    "- Create 1 column of output that contains a message like the one below for each vehicle.\n",
    "\n",
    "```\n",
    "\n",
    "The 1999 audi a4 has a 4 cylinder engine.\n",
    "\n",
    "```\n",
    "\n",
    "- Transform the trans column so that it only contains either manual or auto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[manufacturer: string, model: string, displ: double, year: bigint, cyl: bigint, trans: string, drv: string, cty: bigint, hwy: bigint, fl: string, class: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.createDataFrame(pyd('mpg'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+-----------------------------------------+\n",
      "|manufacturer|model|displ|year|cyl|trans     |drv|cty|hwy|fl |class  |vehicle_info                             |\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+-----------------------------------------+\n",
      "|audi        |a4   |1.8  |1999|4  |auto(l5)  |f  |18 |29 |p  |compact|The 1999 audi a4 has a 4 cylinder engine.|\n",
      "|audi        |a4   |1.8  |1999|4  |manual(m5)|f  |21 |29 |p  |compact|The 1999 audi a4 has a 4 cylinder engine.|\n",
      "|audi        |a4   |2.0  |2008|4  |manual(m6)|f  |20 |31 |p  |compact|The 2008 audi a4 has a 4 cylinder engine.|\n",
      "|audi        |a4   |2.0  |2008|4  |auto(av)  |f  |21 |30 |p  |compact|The 2008 audi a4 has a 4 cylinder engine.|\n",
      "|audi        |a4   |2.8  |1999|6  |auto(l5)  |f  |16 |26 |p  |compact|The 1999 audi a4 has a 6 cylinder engine.|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+-----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\n",
    "    'vehicle_info',\n",
    "    F.concat(\n",
    "    F.lit('The '),\n",
    "    df.year,\n",
    "    F.lit(' '),\n",
    "    df.manufacturer,\n",
    "    F.lit(' '),\n",
    "    df.model,\n",
    "    F.lit(' has a '),\n",
    "    df.cyl,\n",
    "    F.lit(' cylinder engine.')\n",
    "    )\n",
    ").show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+-----------------------------------------+\n",
      "|manufacturer|model|displ|year|cyl|trans     |drv|cty|hwy|fl |class  |vehicle_info                             |\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+-----------------------------------------+\n",
      "|audi        |a4   |1.8  |1999|4  |auto(l5)  |f  |18 |29 |p  |compact|The 1999 audi a4 has a 4 cylinder engine.|\n",
      "|audi        |a4   |1.8  |1999|4  |manual(m5)|f  |21 |29 |p  |compact|The 1999 audi a4 has a 4 cylinder engine.|\n",
      "|audi        |a4   |2.0  |2008|4  |manual(m6)|f  |20 |31 |p  |compact|The 2008 audi a4 has a 4 cylinder engine.|\n",
      "|audi        |a4   |2.0  |2008|4  |auto(av)  |f  |21 |30 |p  |compact|The 2008 audi a4 has a 4 cylinder engine.|\n",
      "|audi        |a4   |2.8  |1999|6  |auto(l5)  |f  |16 |26 |p  |compact|The 1999 audi a4 has a 6 cylinder engine.|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+-----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\n",
    "    'vehicle_info',\n",
    "    F.concat(\n",
    "    F.lit('The '),\n",
    "    df.year,\n",
    "    F.lit(' '),\n",
    "    df.manufacturer,\n",
    "    F.lit(' '),\n",
    "    df.model,\n",
    "    F.lit(' has a '),\n",
    "    df.cyl,\n",
    "    F.lit(' cylinder engine.')\n",
    "    )\n",
    ").show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+-----+----+---+------+---+---+---+---+-------+\n",
      "|manufacturer|model             |displ|year|cyl|trans |drv|cty|hwy|fl |class  |\n",
      "+------------+------------------+-----+----+---+------+---+---+---+---+-------+\n",
      "|audi        |a4                |1.8  |1999|4  |auto  |f  |18 |29 |p  |compact|\n",
      "|audi        |a4                |1.8  |1999|4  |manual|f  |21 |29 |p  |compact|\n",
      "|audi        |a4                |2.0  |2008|4  |manual|f  |20 |31 |p  |compact|\n",
      "|audi        |a4                |2.0  |2008|4  |auto  |f  |21 |30 |p  |compact|\n",
      "|audi        |a4                |2.8  |1999|6  |auto  |f  |16 |26 |p  |compact|\n",
      "|audi        |a4                |2.8  |1999|6  |manual|f  |18 |26 |p  |compact|\n",
      "|audi        |a4                |3.1  |2008|6  |auto  |f  |18 |27 |p  |compact|\n",
      "|audi        |a4 quattro        |1.8  |1999|4  |manual|4  |18 |26 |p  |compact|\n",
      "|audi        |a4 quattro        |1.8  |1999|4  |auto  |4  |16 |25 |p  |compact|\n",
      "|audi        |a4 quattro        |2.0  |2008|4  |manual|4  |20 |28 |p  |compact|\n",
      "|audi        |a4 quattro        |2.0  |2008|4  |auto  |4  |19 |27 |p  |compact|\n",
      "|audi        |a4 quattro        |2.8  |1999|6  |auto  |4  |15 |25 |p  |compact|\n",
      "|audi        |a4 quattro        |2.8  |1999|6  |manual|4  |17 |25 |p  |compact|\n",
      "|audi        |a4 quattro        |3.1  |2008|6  |auto  |4  |17 |25 |p  |compact|\n",
      "|audi        |a4 quattro        |3.1  |2008|6  |manual|4  |15 |25 |p  |compact|\n",
      "|audi        |a6 quattro        |2.8  |1999|6  |auto  |4  |15 |24 |p  |midsize|\n",
      "|audi        |a6 quattro        |3.1  |2008|6  |auto  |4  |17 |25 |p  |midsize|\n",
      "|audi        |a6 quattro        |4.2  |2008|8  |auto  |4  |16 |23 |p  |midsize|\n",
      "|chevrolet   |c1500 suburban 2wd|5.3  |2008|8  |auto  |r  |14 |20 |r  |suv    |\n",
      "|chevrolet   |c1500 suburban 2wd|5.3  |2008|8  |auto  |r  |11 |15 |e  |suv    |\n",
      "+------------+------------------+-----+----+---+------+---+---+---+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\n",
    "    'trans',\n",
    "    F.regexp_replace(\n",
    "    'trans',\n",
    "    r'(\\(\\w+\\))',\n",
    "    '')\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the tips dataset as a spark dataframe.\n",
    "\n",
    "- What percentage of observations are smokers?\n",
    "- Create a column that contains the tip percentage\n",
    "- Calculate the average tip percentage for each combination of sex and smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(pyd('tips'))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38114754098360654"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((df.where(F.col('smoker')=='Yes').count())\n",
    "/(df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smoker\n",
       "No     0.618852\n",
       "Yes    0.381148\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pyd('tips')\n",
    "df1.smoker.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|tip_pct|\n",
      "+----------+----+------+------+---+------+----+-------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2| 0.0594|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3| 0.1605|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3| 0.1666|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 0.1398|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4| 0.1468|\n",
      "+----------+----+------+------+---+------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\n",
    "    'tip_pct',\n",
    "    F.round(df.tip/df.total_bill,4)\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:=============================>                            (4 + 4) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-----------+\n",
      "|   sex|smoker|avg_tip_pct|\n",
      "+------+------+-----------+\n",
      "|  Male|    No|     0.1607|\n",
      "|Female|    No|     0.1569|\n",
      "|  Male|   Yes|     0.1528|\n",
      "|Female|   Yes|     0.1822|\n",
      "+------+------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupBy('sex','smoker').agg(\n",
    "    F.round(F.avg(df.tip/df.total_bill),4).alias('avg_tip_pct')\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. \n",
    "\n",
    "Use the Seattle weather dataset referenced in the lesson to answer the questions below.\n",
    "\n",
    "- Convert the temperatures to fahrenheit.\n",
    "- Which month has the most rain, on average?\n",
    "- Which year was the windiest?\n",
    "- What is the most frequent type of weather in January?\n",
    "- What is the average high and low temperature on sunny days in July in 2013 and 2014?\n",
    "- What percentage of days were rainy in Q3 of 2015?\n",
    "- For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "|2012-01-04|         20.3|    12.2|     5.6| 4.7|   rain|\n",
      "|2012-01-05|          1.3|     8.9|     2.8| 6.1|   rain|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather = vega.seattle_weather().assign(date=lambda df: df.date.astype(str))\n",
    "df = spark.createDataFrame(weather)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01|          0.0|   55.04|    41.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|   51.08|   37.04| 4.5|   rain|\n",
      "|2012-01-03|          0.8|   53.06|   44.96| 2.3|   rain|\n",
      "|2012-01-04|         20.3|   53.96|   42.08| 4.7|   rain|\n",
      "|2012-01-05|          1.3|   48.02|   37.04| 6.1|   rain|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# f = c * 9/5) + 32\n",
    "df.withColumn(\n",
    "    'temp_min',\n",
    "    ((df.temp_min * 9) / 5) + 32\n",
    "    ).withColumn(\n",
    "        'temp_max',\n",
    "        ((df.temp_max * 9) / 5) + 32\n",
    "    ).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| mo|avg_rain|\n",
      "+---+--------+\n",
      "| 11|     5.4|\n",
      "+---+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(df.withColumn('mo',F.month('date')\n",
    "    ).groupBy('mo'\n",
    "        ).agg(F.round(F.avg('precipitation'),1\n",
    "            ).alias('avg_rain')\n",
    "            ).sort(F.col('avg_rain').desc())\n",
    "            ).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|  yr|avg_wind|\n",
      "+----+--------+\n",
      "|2012|  3.4008|\n",
      "+----+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "((df.withColumn('yr',F.year('date')\n",
    "    ).groupBy('yr'\n",
    "        ).agg(F.round(F.avg('wind'),4\n",
    "                ).alias('avg_wind')\n",
    "            ).sort(F.col('avg_wind').desc())\n",
    "            )).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('mo',F.month('date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|weather|freq|\n",
      "+-------+----+\n",
      "|    fog|  38|\n",
      "+-------+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.where(df.mo==1\n",
    "    ).groupBy(df.weather\n",
    "        ).agg(F.count(df.weather\n",
    "            ).alias('freq')).sort(F.col('freq').desc()).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('yr',F.year('date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|avg_low|avg_high|\n",
      "+-------+--------+\n",
      "|  14.18|   26.83|\n",
      "+-------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(df.where(df.mo==7\n",
    "    ).where(df.yr>2012\n",
    "    ).where(df.yr<2015\n",
    "    ).where(df.weather=='sun'\n",
    "    ).select(\n",
    "        F.round(F.avg('temp_min'),2).alias('avg_low'),\n",
    "        F.round(F.avg('temp_max'),2).alias('avg_high')\n",
    "    )\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.where(df.weather=='rain')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 43:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|pct_rainy_days|\n",
      "+--------------+\n",
      "|        2.8152|\n",
      "+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(df.where(df.mo>9).where(df.yr==2015\n",
    "    ).select(\n",
    "        F.round((df.where(df.weather=='rain')).count()\n",
    "        /F.count(df.weather),4).alias('pct_rainy_days')\n",
    "    )\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+\n",
      "|  yr|pct_rain_days|\n",
      "+----+-------------+\n",
      "|2012|       0.4849|\n",
      "|2013|       0.4164|\n",
      "|2014|        0.411|\n",
      "|2015|       0.3945|\n",
      "+----+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(df.where(df.precipitation>0\n",
    "    ).groupBy('yr'\n",
    "        ).agg(F.count(df.precipitation).alias('avg_rain_days')\n",
    "            ).select('yr',F.round(F.expr('avg_rain_days / 365'),4\n",
    "                ).alias('pct_rain_days'))\n",
    "                ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/25 09:31:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "[Stage 0:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Installation test\n",
    "import pyspark\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "spark.range(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/25 09:31:43 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import pyspark\n",
    "\n",
    "nprocs = multiprocessing.cpu_count()\n",
    "\n",
    "spark = (pyspark.sql.SparkSession.builder\n",
    " .master('local')\n",
    " .config('spark.jars.packages', 'mysql:mysql-connector-java:8.0.16')\n",
    " .config('spark.driver.memory', '4G')\n",
    " .config('spark.driver.cores', nprocs)\n",
    " .config('spark.sql.shuffle.partitions', nprocs)\n",
    " .appName('MySparkApplication')\n",
    " .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
